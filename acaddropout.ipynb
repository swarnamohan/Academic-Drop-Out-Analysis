{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "name": ""
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\n\n# Read Dataset\nacaddropout = pd.read_csv('acaddropout.csv')\n\n# Split dataset into features and labels\nacaddropout1 = acaddropout.drop('Target', axis =1)\nlabels = acaddropout.Target\n\n# Create dataset without units\nacaddropout2 = acaddropout.drop(['Target','Curricular units 1st sem credited','Curricular units 1st sem enrolled',\n                                 'Curricular units 1st sem evaluations','Curricular units 1st sem approved',\n                                 'Curricular units 1st sem grade','Curricular units 1st sem without evaluations',\n                                 'Curricular units 2nd sem credited','Curricular units 2nd sem enrolled',\n                                 'Curricular units 2nd sem evaluations','Curricular units 2nd sem approved',\n                                 'Curricular units 2nd sem grade','Curricular units 2nd sem without evaluations'], axis =1)\n\n\n#print(acaddropout.head())\n\nfeatures = pd.get_dummies(acaddropout1, columns=[\"Marital status\", \"Application Mode\", \"Application order\", \"Course\", \n                                                    \"attendance_time\", \"Previous Qualification\", \"Nationality\", \"Mother Qualification\",\"Father Qualification\",\n                                                    \"Mother Occupation\",\"Father Occupation\", \"Gender\"])\n\nfeatures2 = pd.get_dummies(acaddropout2, columns=[\"Marital status\", \"Application Mode\", \"Application order\", \"Course\", \n                                                    \"attendance_time\", \"Previous Qualification\", \"Nationality\", \"Mother Qualification\",\"Father Qualification\",\n                                                    \"Mother Occupation\",\"Father Occupation\", \"Gender\"])\n\nprint(features.head()) \nprint(features2.head())\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "   Previous qualification grade  Admission grade  ...  Gender_Female  Gender_Male\n0                         122.0            127.3  ...              0            1\n1                         160.0            142.5  ...              0            1\n2                         122.0            124.8  ...              0            1\n3                         122.0            119.6  ...              1            0\n4                         100.0            141.5  ...              1            0\n\n[5 rows x 153 columns]\n   Previous qualification grade  Admission grade  ...  Gender_Female  Gender_Male\n0                         122.0            127.3  ...              0            1\n1                         160.0            142.5  ...              0            1\n2                         122.0            124.8  ...              0            1\n3                         122.0            119.6  ...              1            0\n4                         100.0            141.5  ...              1            0\n\n[5 rows x 141 columns]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Split dataset into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.30, random_state = 42)\nX_train2, X_test2, y_train2, y_test2 = train_test_split(features2, labels, test_size=0.30, random_state = 42)\n\n\n# Using Grid Search to find the best parameters\nparam_grid1 = { \n    'n_estimators': [200],\n    'max_features': [153],\n    'max_depth' : [9,11],\n    'criterion' :['gini'],\n    'min_samples_split':[2]\n    }\n\nparam_grid2 = { \n    'n_estimators': [100,150,200],\n    'max_features': [141],\n    'max_depth' : [9,11,13,15],\n    'criterion' :['gini'],\n    'min_samples_split':[2,3]\n    }\n\n# Training RF Models with K-Fold of 5 \nrf_models = GridSearchCV(RandomForestClassifier(random_state = 42), param_grid=param_grid1, cv=5, verbose=1)\nrf_models.fit(X_train, y_train)\nprint(rf_models.best_params_)\n\n# Training RF Models with K-Fold of 5 \nrf_models2 = GridSearchCV(RandomForestClassifier(random_state = 42), param_grid=param_grid2, cv=5, verbose=1)\nrf_models2.fit(X_train2, y_train2)\nprint(rf_models2.best_params_)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n{'criterion': 'gini', 'max_depth': 9, 'max_features': 153, 'min_samples_split': 2, 'n_estimators': 200}\nFitting 5 folds for each of 24 candidates, totalling 120 fits\n{'criterion': 'gini', 'max_depth': 13, 'max_features': 141, 'min_samples_split': 2, 'n_estimators': 100}",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "predictions = rf_models.predict(X_test)\npredictions2 = rf_models2.predict(X_test2)\n\n# Print the Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(predictions, y_test))\n\n# Print Feature Importance\nfeature_importance = pd.DataFrame(data={\"features\":X_test.columns, \"importance\":rf_models.best_estimator_.feature_importances_*100})\nprint(\"Feature Importance\")\nprint(feature_importance.sort_values('importance', ascending=False).head(10))\n\n# Print the 2nd Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(predictions2, y_test2))\n\n# Print 2nd Model Feature Importance\nfeature_importance2 = pd.DataFrame(data={\"features\":X_test2.columns, \"importance\":rf_models2.best_estimator_.feature_importances_*100})\nprint(\"Feature Importance\")\nprint(feature_importance2.sort_values('importance', ascending=False).head(10))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Accuracy: 0.7643072289156626\nFeature Importance\n                                features  importance\n18     Curricular units 2nd sem approved   47.021838\n5                Tuition fees up to date    5.381794\n19        Curricular units 2nd sem grade    3.576575\n11  Curricular units 1st sem evaluations    3.161188\n1                        Admission grade    2.810703\n0           Previous qualification grade    2.766756\n12     Curricular units 1st sem approved    2.445071\n7                      Age at enrollment    2.434991\n16     Curricular units 2nd sem enrolled    2.350735\n17  Curricular units 2nd sem evaluations    2.331269\nAccuracy: 0.641566265060241\nFeature Importance\n                        features  importance\n5        Tuition fees up to date   15.364829\n1                Admission grade    9.007001\n7              Age at enrollment    7.216262\n0   Previous qualification grade    6.636007\n6             Scholarship holder    6.560176\n11                           GDP    4.448183\n9              Unemployment rate    3.366316\n46                   Course_9500    2.585017\n10                Inflation rate    2.410330\n41                   Course_9119    2.042362",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}
